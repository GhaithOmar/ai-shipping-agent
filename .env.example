# Base & adapter
BASE_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
ADAPTER_ID=GhaithOmar/ai-shipping-agent-llama3.1-8b-lora-day4

# Optional: forward to a remote GPU inference server (HF Endpoint/Space)
REMOTE_INFERENCE_URL=

# Optional: open-model fallback for demos without gated access
FALLBACK_BASE=Qwen/Qwen2.5-3B-Instruct

# LLM / HF
HF_TOKEN=your_huggingface_token_here

# Qdrant (local file store is fine if you use local Qdrant, but keep vars for Docker Day 7)
QDRANT_HOST=127.0.0.1
QDRANT_PORT=6333
QDRANT_COLLECTION=shipping_kb

# Agent toggles
AGENT_ENABLE=true
AGENT_TOP_K=4
